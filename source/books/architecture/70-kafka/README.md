# kafka

kafka 是消息中间件中的佼佼者，它支持高并发，整体使用发布/订阅的模式，自带高可用和负载均衡等功能。



kafka 的安装部署推荐使用 Docker 的方式，简单方便。安装 kafka之前需要安装 zookeeper，因为 kafka 依赖 zookeeper 存消息的元数据。

Kafka 中创建一个逻辑消息队列称之为创建一个 topic。为了保证负载均衡和高可用，kafka中使用分区和副本的方式，还有集群，一个 kafka 集群中的节点称之为 broker。

一个 topic 设置多个分区，适量提高分区的数量可以提高消息消息的吞吐量，但是要在节点机器处理能力的范围内。生产者产生数据按照指定策略存放在一个 topic 中的一个分区中。站在 topic 的角度，分区中消息的存放是无序的。但是站在一个分区或者处理这个分区的消息者来说，分区中的消息是有序的。分区数量和消费者数量一致比较合适。

为了保证分区的高可用，每个分区可以设置多个副本。副本就是主从的概念。副本数量要少于等于节点数量。每个分区都有一个主副本，或者多个从副本。主副本负责消息的读写，从副本进负责备份。当主副本不可用时，在从副本中选择一个成为新的主副本。

数据或者消息，存放在消息队列中，本质上是存在硬盘文件上。因为 kafka支持数据持久化，默认储存近 7 天的数据，当然也可以修改，也支持按照消息总容量做配置。

存在文件中消息的组织方式非常重要。因为是写消息，需要保证高并发写场景下，高性能的把数据写到消息队列中。

kafka 中每个分区在硬盘上就是一个文件夹。文件夹中存放两类文件，一类是 `*.log` 结尾的数据文件，存放消息；一类是 `*.index` 结尾的索引文件，记录消息的索引信息，加快查询速度。

并且每类文件按照数据的先后顺序，分段保存，写数据当然也是顺序写入。一个段称之为一个 Segment。一个段内的两个文件，按照其实偏移量命名文件名。比如第一段的文件命名为：`0000000000000000.log` 和 `0000000000000000.index`。第二个段的起始偏移量是 32434，那么第二个段的文件为：`0000000000032434.log` 和 `0000000000032434.index`。



在一个段内，数据的写入使用相对便宜量，这样可以减少数值大小。并且采用稀疏索引的方式构建索引结构，每次查询按照二分法，找到待小于或等于待查询偏移量的最大那个稀疏索引节点。在这个节点上按照顺序查询需要的数据。这中稀疏索引的构建方式，充分减小索引文件的大小。整体使用空间换时间的方式，提高并发写场景下高校记录消息的需求。

写数据的三个 ACKS 策略。生产者写消息，

- 如果写策略是 `0`，则表示异步写数据，无法等待主分区副本。这种方式效率最高，但数据丢失风险加高。
- 如果写策略是 `1`，则表示写数据需要等待主分区副本把数据保存到硬盘再结束。这种方式在效率和安全之间保持了平衡。
- 如果写策略是 `all`，则表示写数据需要主分区完车给后，再同步给所有副本，然后才能结束。这种方式数据是最安全的。



生产者如何选择一个分区存数据。多个分区有负载均衡的好处。存在三种写入情况，会按照情况选择不同的分区写入消息数据。

- 如果写入时指定了分区，则把消息写在指定分区上。
- 如果写入时没有指定分区，但是指定了消息的 key，则会按照 key 的哈希值计算出来一个分区。
- 如果没有指定分区，也没有指定 key，则会按照轮询的方式选出一个分区。



消费者如何消费数据。一般有两种消费数据的方式，一个是主动拉数据来消费（PULL）。一个是被动收到推来数据（PUSH）。后者主要用在消费者的消费能力远远高于生产者的场景。如果是大流量高并发场景，主要使用 PULL 的方式。kafka 中消费者采用 PULL 的方式消费数据。

kafka 是居于发布订阅的方式在生产者和消费者之间传递消息，存在多个消费者重复消息一个消息的可能。为了避免这种情况，kafka 定义了消费者组的概念。

一个消费组内的消费者竞争消息，同一个分区的消息在同一个时间只能被一个消费组内的一个消费者消费。在这个程度上，消费者组内的消费者之间是点对点的关系。但是 kafka整体架构依然是发布/订阅模式的。一个消费可以被多个消费这个消费，且消费后不会删除该消息。

