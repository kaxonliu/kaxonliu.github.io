# k8s 网络

## pod 的创建流程

创建 pod 时，会先创建一个 pause 容器，并且将网络模式设置为 None。

kubelet 会调用网络插件，来为 pause容器初始化好网络。

pause 容器的网络打通之后，根据指定的业务镜像拉起业务容器。

业务容器启动之后会设置网络模式为 container 模式与 pause 容器共享网络。

~~~alert type=note
以flannel插件的vxlan网络模式为例 <br>
先为pause容器创建一个veth，一端放在pause容器内,另外一端接到网桥上（cni0）<br>
pause容器 -----> cni0网桥------> flannel.1设备------>物理网卡eth0------>外部网络
~~~



## 跨主机网络通信网络基础

### vlan

二层网络内主机通信，主机可以在不同的物理位置，通过二层交换机连接。如果主机数量多，可以把多个二层交换机使用 TRUNK 口连接，组成一个大的二层网络。

如果想把这个二层网络划分为不同的子局域网，使用 vlan 技术，具体使用 vlan id 标识子网。

vlan 模式的问题：

- 物理网络必须是二层的（限制底层网络的灵活性）
- vlan id最多4096（限制了网络的规模）				



### GRE

使用现有的三层 IP 协议当搬运工，封装自定义协议。

- 封包解包设备：br-tun 设备
- Delivery 头：ip 协议
- GRE 头： GRE id 等同于 vlan id，用于区分不同租户的局域网
- Playload：内层包，即真实要发送的包



GRE 问题：

- 每一个节点都需要维护与其他所有物理节点的隧道关系。
- 一个二层会广播到所有其他物理节点（不支持组播）

GRE 总结：在集群规模大了的情况下，GRE 效率会变得非常慢。





### vxlan

使用现有的四层 UDP 协议当搬运工，封装自定义协议。

- 封包解包设备：VTEP设备（k8s会在每台物理上创建flannel.1）
- Delivery 头：UDP协议
- Vxlan 头：vni id号， 用于区分不同租户的局域网
- Playload：内层包，即真实要发送的包

如何解决 GRE 的问题的：

- 支持组播，新节点都会加入组里，发包时组内的机器都会收到广播包，所以不需要维护隧道信息了，并且基于udp协议搬运包是无状态的
- vni id 是 使用 24 位的 id，几乎没有子网数量的限制。

~~~alert type=note
k8s 中 flannel 基于 vxlan 的模式，vni id 号是固定的，固定值是1；并且 pod 的 mac 地址是静态，由flanneld 进程维护，进行二层通信前不需要发送 arp 广播获取。
~~~



### CIDR

CIDR 是一个新的 IP 地址分配方式，采用的是可变长的子网掩码，称之为无类别域间路由（消除传统的分A类、B类以及子网划分概念，重新开始） 

在 CIDR 中，IP地址的表达格式为：“IP地址/前缀长度” 。

CIDR 可以把 IP 地址分配和子网划分变得实用和灵活，减少 IP 地址的浪费等。



## 在k8s中关于网络划分要考虑的问题

需要考虑的问题：

- 每个 pod 都要有一个独一无二的 ip 地址（因为我们是大二层网络，ip不能冲突）。
- POD 的 IP 地址要够标识 pod 来自于哪台机器。



初始部署时为 pod 的网络指定一个大段（`podSubnet: 10.244.0.0/16`，这个配置会创建 2的8次方，也就是 256 个子网络），k8s 会在该大段的基础上进行子网划分，每个节点被分配走一个子网段，该节点上启动的 Pod 都属于自己分配到的网段。

这么做的好处：

- 每个节点都有自己的一个网段，具有标识性。
- 在访问某个 pod 的 ip 地址时，可以直接确定该 pod 属于哪台物理机，发包效率更高。



虽然不同物理节点上的 pod 拥有各自的网段，看起来像是在不同的网里，但是所有的 pod 都是可以直接二层通信的，ip 地址只是一种标识其独一无二性的一直标识方式。



## flannel 插件

可以有两种模式，vxlan（默认）、host-gw

#### vxlan 模式

基于 vxlan 协议，采用 vxlan 模式构建的是大二层网络，底层支撑的物理网络可以是二层也可以是三层。

每个物理节点都有自己的一个24为子网掩码的网段，用于标识某个 pod 归属的宿主机。

会在每个宿主机上创建两个设备

- cni0：网桥设备-就是一个虚拟二层交换机
- flannel.1: 是一个 VTEP 设备，负责 vxlan 协议的封包解包。

vxlan 模式管理的每个 pod 都会通过 veth 对链接到 cni0 网桥上。

~~~bash
# veth对查看
# 在pod内查看
cat /sys/class/net/eth0/iflink
					
# 宿主机上查看cni0关联的veth设备
bridge link show
~~~



